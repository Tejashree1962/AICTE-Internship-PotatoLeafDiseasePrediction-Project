{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bdc451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2f626c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\TRUPTI-PARAB\\Desktop\\PLD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "current_directory = os.getcwd()\n",
    "train_path = os.path.join(current_directory, \"dataset\",\"Train\")\n",
    "valid_path = os.path.join(current_directory, \"dataset\",\"Valid\")\n",
    "test_path = os.path.join(current_directory, \"dataset\",\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733d6b84",
   "metadata": {},
   "source": [
    "## Parameter Breakdown\n",
    "\n",
    "### `train_path`\n",
    "- **Description**: The path to the directory containing the training images.\n",
    "- **Details**: This directory should have subdirectories, with each subdirectory named after a class label, containing images of that class.\n",
    "\n",
    "---\n",
    "\n",
    "### `labels=\"inferred\"`\n",
    "- **Description**: The labels for the images are inferred from the subdirectory names in the `train_path`.\n",
    "- **Example**: If `train_path` contains subdirectories `cats` and `dogs`, labels will be assigned as `cats = 0` and `dogs = 1` (or similar).\n",
    "\n",
    "---\n",
    "\n",
    "### `label_mode=\"categorical\"`\n",
    "- **Description**: Specifies the type of labels.\n",
    "  - `\"categorical\"`: Labels are returned as one-hot encoded vectors.\n",
    "  - `\"int\"`: Labels are returned as integers.\n",
    "  - `None`: No labels are returned.\n",
    "- **Details**: Here, labels are one-hot encoded, useful for classification tasks.\n",
    "\n",
    "---\n",
    "\n",
    "### `class_names=None`\n",
    "- **Description**: Automatically determines class names from the subdirectory names.\n",
    "- **Details**: You can specify a list like `['cats', 'dogs']` to manually define the class names.\n",
    "\n",
    "---\n",
    "\n",
    "### `color_mode=\"rgb\"`\n",
    "- **Description**: Specifies the image color mode.\n",
    "  - `\"rgb\"`: Loads 3-channel color images.\n",
    "  - `\"grayscale\"`: Loads single-channel grayscale images.\n",
    "  - `\"rgba\"`: Loads 4-channel color images.\n",
    "- **Details**: Here, images are loaded in RGB mode.\n",
    "\n",
    "---\n",
    "\n",
    "### `batch_size=32`\n",
    "- **Description**: The number of images to be processed in a single batch during training.\n",
    "- **Details**: Affects memory usage and training speed.\n",
    "\n",
    "---\n",
    "\n",
    "### `image_size=(128, 128)`\n",
    "- **Description**: Resizes all images to the specified dimensions (128x128 pixels in this case).\n",
    "- **Details**: Helps standardize input dimensions for the neural network.\n",
    "\n",
    "---\n",
    "\n",
    "### `shuffle=True`\n",
    "- **Description**: Randomly shuffles the images before creating batches.\n",
    "- **Details**: Helps reduce overfitting and ensures a diverse input distribution.\n",
    "\n",
    "---\n",
    "\n",
    "### `seed=None`\n",
    "- **Description**: Used to set a random seed for reproducibility of the shuffle.\n",
    "- **Details**: If `None`, results may vary across runs.\n",
    "\n",
    "---\n",
    "\n",
    "### `validation_split=None`\n",
    "- **Description**: Specifies the fraction of data to be set aside for validation.\n",
    "- **Example**: `validation_split=0.2` reserves 20% of data for validation.\n",
    "\n",
    "---\n",
    "\n",
    "### `subset=None`\n",
    "- **Description**: Specifies whether this dataset is for training or validation when `validation_split` is set.\n",
    "- **Options**: `\"training\"` or `\"validation\"`.\n",
    "- **Details**: Must be used with `validation_split`.\n",
    "\n",
    "---\n",
    "\n",
    "### `interpolation=\"bilinear\"`\n",
    "- **Description**: Method used to resize the images.\n",
    "- **Options**: `\"nearest\"`, `\"bilinear\"`, `\"bicubic\"`, etc.\n",
    "- **Details**: `\"bilinear\"` is smooth and works well for resizing.\n",
    "\n",
    "---\n",
    "\n",
    "### `follow_links=False`\n",
    "- **Description**: If `True`, follows symbolic links to access images.\n",
    "\n",
    "---\n",
    "\n",
    "### `crop_to_aspect_ratio=False`\n",
    "- **Description**: If `True`, crops images to maintain their original aspect ratio before resizing.\n",
    "- **Details**: If `False`, images are resized to `image_size` directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "546b587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 865 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# function is used to create an image dataset from a directory structure where images are organized into subdirectories representing class labels\n",
    "training_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    # batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    # seed=None,\n",
    "    # validation_split=None,\n",
    "    # subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    # follow_links=False,\n",
    "    # crop_to_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63c58a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy']\n"
     ]
    }
   ],
   "source": [
    "# Get the class labels\n",
    "labels = training_set.class_names\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55d60128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    valid_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    # batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    # seed=None,\n",
    "    # validation_split=None,\n",
    "    # subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    # follow_links=False,\n",
    "    # crop_to_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d89cade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding='same',activation='relu',input_shape=[128,128,3]))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3,padding='same',activation='relu',input_shape=[128,128,3]))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=256,kernel_size=3,padding='same',activation='relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=256,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=512,kernel_size=3,padding='same',activation='relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=512,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dense(units=1500,activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dropout(0.4))\n",
    "\n",
    "cnn.add(tf.keras.layers.Dense(units=3,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ace6f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b29c6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 128, 128, 32)      896       \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 126, 126, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 63, 63, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 63, 63, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 61, 61, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 30, 30, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 28, 28, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 14, 14, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 14, 14, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 6, 6, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 2, 2, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1500)              3073500   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1500)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 4503      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,790,227\n",
      "Trainable params: 7,790,227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43ae5aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 415s 15s/step - loss: 0.0804 - accuracy: 0.9734 - val_loss: 0.1165 - val_accuracy: 0.9600\n",
      "Epoch 2/3\n",
      "28/28 [==============================] - 444s 16s/step - loss: 0.0615 - accuracy: 0.9803 - val_loss: 0.2065 - val_accuracy: 0.9267\n",
      "Epoch 3/3\n",
      "28/28 [==============================] - 343s 12s/step - loss: 0.0999 - accuracy: 0.9595 - val_loss: 0.1215 - val_accuracy: 0.9533\n"
     ]
    }
   ],
   "source": [
    "training_history = cnn.fit(x=training_set,validation_data=validation_set,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84bc4919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 92s 3s/step - loss: 0.0538 - accuracy: 0.9827\n",
      "Training accuracy: 0.9826589822769165\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = cnn.evaluate(training_set)\n",
    "print('Training accuracy:', train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f92b393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 35s 3s/step - loss: 0.1215 - accuracy: 0.9533\n",
      "Validation accuracy: 0.95333331823349\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = cnn.evaluate(validation_set)\n",
    "print('Validation accuracy:', val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3d15da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('trained_plant_disease_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "430810a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.08035481721162796, 0.061512984335422516, 0.09985923767089844],\n",
       " 'accuracy': [0.973410427570343, 0.9803467988967896, 0.9595375657081604],\n",
       " 'val_loss': [0.116522878408432, 0.20650269091129303, 0.12149825692176819],\n",
       " 'val_accuracy': [0.9599999785423279, 0.9266666769981384, 0.95333331823349]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5556213c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (10,) and (3,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m11\u001b[39m)]\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtraining_history\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbrown\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTraining Accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs,training_history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m],color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m,label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo. of Epochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\TRUPTI-PARAB\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\pyplot.py:3829\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3821\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   3822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[0;32m   3823\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3827\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3828\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[1;32m-> 3829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   3830\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m   3831\u001b[0m         scalex\u001b[38;5;241m=\u001b[39mscalex,\n\u001b[0;32m   3832\u001b[0m         scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   3833\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m   3834\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3835\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\TRUPTI-PARAB\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1777\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1534\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1535\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1536\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1776\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1777\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1778\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1779\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\TRUPTI-PARAB\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_base.py:297\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    295\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    296\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 297\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\TRUPTI-PARAB\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_base.py:494\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    491\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    495\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    498\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10,) and (3,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = [i for i in range(1,11)]\n",
    "plt.plot(epochs,training_history.history['accuracy'],color='brown',label='Training Accuracy')\n",
    "plt.plot(epochs,training_history.history['val_accuracy'],color='green',label='Validation Accuracy')\n",
    "plt.xlabel('No. of Epochs')\n",
    "plt.title('Visualization of Accuracy Result')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e83c2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
